## Codebase Patterns
- Main artifact: ~/.claude/tom/transcript_memory.py (single file, ~800-1000 lines, zero external deps)
- Database: ~/.claude/tom/transcript-memory.db (SQLite with WAL mode and FTS5)
- JSONL transcripts: ~/.claude/projects/{project-name}/*.jsonl — each line is JSON with "type" field (user|assistant|progress)
- Session index: ~/.claude/projects/{project-name}/sessions-index.json — pre-computed metadata
- Subagent transcripts: ~/.claude/projects/{project-name}/{session-uuid}/subagents/agent-*.jsonl
- Tool calls in assistant messages: message.content[] with type=="tool_use", fields: id, name, input
- Tool results in user messages: message.content[] with type=="tool_result", fields: tool_use_id, content, is_error
- Match tool results to calls via tool_use_id field
- Assistant reasoning text: message.content[] with type=="text", field: text
- Token usage: message.usage.{input_tokens, output_tokens, cache_read_input_tokens}
- Timestamps: ISO 8601 with Z suffix on every entry
- Entry metadata: uuid, parentUuid, sessionId, cwd, gitBranch, agentId (for subagents)
- Secret redaction patterns (14): sk-*, ghp_*, gho_*, ghs_*, github_pat_*, Bearer *, Basic *, token *, xox*, AKIA*, eyJ*, password*, npm_*, pypi-*
- FTS5 content tables: use `INSERT INTO fts(fts) VALUES('rebuild')` to sync; do NOT insert/update FTS rows directly when using content= option
- Foreign key constraints: ensure all referenced sessions exist before inserting messages (collect session_ids from all messages)
- tool_output is truncated to 10KB in DB to keep size manageable; summary is 1KB redacted
- Existing ToM bootstrap: ~/.claude/tom/bootstrap_tom.py has ToM schema formats (SessionLog, SessionModel, UserModel, BM25)
- PRD with full SQL schema: tasks/prd-transcript-memory.md lines 210-324

## Progress

## 2026-02-07 - US-001: SQLite schema, DB init, and core TranscriptDB class
- Created ~/.claude/tom/transcript_memory.py (~260 lines) with full schema from PRD
- TranscriptDB class with context manager (__enter__/__exit__), WAL mode, FTS5
- 6 core tables: sessions, messages, tool_calls, session_summaries, decisions, ingest_state
- 3 FTS5 virtual tables: tool_calls_fts, summaries_fts, decisions_fts
- 10 indexes matching PRD spec exactly
- argparse CLI with all 8 subcommands: stats, ingest, search, sessions, decisions, tools, daemon, export-tom
- Stats command works: creates DB and prints counts
- Stub methods for all future story features
- **Learnings for future iterations:**
  - No sqlite3 CLI on this machine — verify DB with python3 instead
  - FTS5 content tables (e.g., tool_calls_fts) create _config, _data, _docsize, _idx auxiliary tables automatically
  - File lives OUTSIDE git repo at ~/.claude/tom/ — only ralph-tm/ files get committed
  - SCHEMA_SQL uses IF NOT EXISTS everywhere for idempotent re-runs
---

## 2026-02-07 - US-002: JSONL parser — messages, tool calls, and tool result matching
- Implemented parse_jsonl_file() with byte-offset support and malformed JSON handling
- Extracts user/assistant/progress messages with uuid, session_id, timestamps, token counts, text_content
- Extracts tool_use blocks from assistant content arrays into tool_calls table
- Matches tool_result blocks to tool_calls via tool_use_id, populates output and is_error
- 14 secret redaction regex patterns applied to tool_input_summary and tool_output_summary
- Full ingest: 295 sessions, 149802 messages, 17217 tool calls from 332 JSONL files in ~90s
- FTS5 rebuild working (2356 results for "git" query on tool_calls_fts)
- Files changed: ~/.claude/tom/transcript_memory.py
- **Learnings for future iterations:**
  - FTS5 content tables (content=X) must use 'rebuild' command, NOT direct INSERT/UPDATE on FTS table
  - Must ensure all referenced session_ids exist before inserting messages due to FOREIGN KEY
  - tool_result content can be string or list of {type, text} blocks — handle both
  - Some JSONL files have file-history-snapshot entries (type not user/assistant/progress) — skip them
  - 332 top-level JSONL, 950 in subdirs (subagent transcripts) — US-004 handles subdirs
---

## 2026-02-07 - US-003: Incremental ingestion with byte-offset tracking
- Incremental logic already built into US-002 implementation (byte-offset seek, mtime/size tracking)
- ingest_state table populated: 332 files tracked, bytes_read matches file_size
- Incremental re-run: 1.6s (picks up only new content from active sessions)
- Full re-ingest (--no-incremental): drops all data and re-ingests from scratch in ~90s
- Truncation detection: compares current st_size vs stored file_size, re-ingests from 0 if smaller
- **Learnings for future iterations:**
  - Active Claude Code sessions keep appending to JSONL files — incremental picks these up
  - 332 files × stat() calls take ~0.5s for the scanning phase alone
---

## 2026-02-07 - US-004: Session metadata import and subagent discovery
- Implemented _import_session_indexes() — reads sessions-index.json from all project dirs
- Upserts session metadata: first_prompt, summary, message_count, created_at, git_branch, etc.
- Subagent discovery: scans {session-uuid}/subagents/agent-*.jsonl (950 files found)
- Synthetic session IDs: {parent_session_id}:{agent_id} to keep subagent messages separate
- Updated _find_jsonl_files() to include subagent paths
- Sessions CLI command implemented (get_recent_sessions with project filter and tool_count)
- Stats: 1245 sessions (295 main + 950 subagent), 216K messages, 32K tool calls
- Full ingest: ~38 seconds (optimized with batch commits every 50 files, FK deferred)
- **Learnings for future iterations:**
  - Subagent JSONL entries share parent's sessionId — need synthetic IDs to keep them separate
  - Variable shadowing: `for tc in tc` silently breaks — use different loop variable name
  - PRAGMA foreign_keys=OFF during bulk ingest saves ~30% time
  - FTS rebuild is fast (~1s) even with 32K tool calls — not the bottleneck
  - sessions-index.json format: direct list (not wrapped in object) with sessionId, firstPrompt, summary, etc.
---

## 2026-02-07 - US-005: Enriched session summaries
- Implemented _compute_summaries() — computes per-session goal, outcome, files_touched, tools_used, errors, duration, tokens
- Strips <system-reminder> tags from goal text via regex
- Files extracted from tool_input JSON: file_path, path, notebook_path keys
- 1245 summaries computed in ~40s additional time (total ingest ~80s)
- summaries_fts populated: "kubernetes"→95 results, "harbor"→147 results
- **Learnings for future iterations:**
  - ISO 8601 "Z" suffix needs replacing with "+00:00" for fromisoformat() in Python
  - SQL aggregates (GROUP BY, COUNT, SUM) much faster than Python loops for tool_calls stats
  - Batch commits every 100 summaries keeps memory manageable
---

## 2026-02-07 - US-006: Decision log extraction
- Implemented _extract_decisions() with three decision types:
  - file_created (473): Write tool on files not previously seen in session
  - config_changed (925): Edit tool on .toml/.json/.yaml/.yml/.cfg/.conf/.sh/Dockerfile/Makefile
  - architecture_choice (635): keyword matching (decided/chose/approach/etc.) within 2-message window of tool calls
- decisions_fts FTS5 index: "verifier fix"→5 results
- Total: 2033 decisions across 1245 sessions
- Added decisions CLI command with FTS search
- **Learnings for future iterations:**
  - Architecture choice detection needs message-index-based windowing, not just UUID matching
  - Most architecture choices are in assistant messages that immediately contain tool_use blocks
  - subject extraction: try tool_call file_path first, then quoted terms, then first 60 chars
---

## 2026-02-07 - US-007: Full query interface — Python API and CLI
- Implemented 6 query methods: search_sessions, search_decisions, search_tool_calls, get_session, get_session_tool_calls, get_recent_sessions
- All FTS methods use summaries_fts/decisions_fts/tool_calls_fts JOIN queries
- CLI: search, sessions, decisions, tools commands all support --json and --project flags
- Added _add_common() helper to DRY up argparse --json/--project across subparsers
- **Learnings for future iterations:**
  - argparse parent parser --json doesn't propagate to subparsers — must add per-subparser
  - FTS5 content= tables require JOIN on rowid for queries (not direct content lookup)
---

## 2026-02-07 - US-008: Live daemon mode with polling
- Implemented daemon command: polling loop every 2s, PID file, graceful signal shutdown
- --once flag for single poll cycle (hook/cron use)
- Reuses incremental ingest logic + subagent detection from US-003/US-004
- PID file at ~/.claude/tom/transcript-memory.pid, cleaned up on exit
- Signal handling via signal.signal(SIGTERM/SIGINT)
- **Learnings for future iterations:**
  - Python backgrounded with & + kill/wait pattern works well for testing daemon
  - _compute_summaries and _extract_decisions are idempotent (LEFT JOIN checks for existing)
---

## 2026-02-07 - US-009: Session-end hook integration
- Hook already created by previous iteration at ~/.claude/hooks/stop.sh (755 permissions)
- Optimized --session ingest path: skips _import_session_indexes(), scopes _compute_summaries() and _extract_decisions() to just the ingested session IDs
- Added session_ids parameter to _compute_summaries() and _extract_decisions() for scoped post-processing
- Removed self-import bug in daemon (was doing `from transcript_memory import _collect_entries_from_file` instead of using module-level function directly)
- --session ingest timing: 3.6s (well under 5s target)
- DB lock retry in cmd_ingest: catches sqlite3.OperationalError("locked"), retries once after 1s, then silently skips
- install-hook command is idempotent: checks for "transcript_memory.py" in existing stop.sh content
- Files changed: ~/.claude/tom/transcript_memory.py
- **Learnings for future iterations:**
  - _compute_summaries and _extract_decisions accept optional session_ids set to scope work — much faster for single-session hook ingest
  - The main artifact lives outside git; only ralph-tm/ files need to be committed
  - Daemon had a self-import (`from transcript_memory import ...`) that worked when the file was in sys.path but was unnecessary since the function is module-level
---
