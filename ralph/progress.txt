# Ralph Progress Log
Started: 2026-02-01

## Codebase Patterns
- Agent config is controlled by `BASELINE_MCP_TYPE` env var in `claude_baseline_agent.py`
- The 3-config comparison uses: `none` (Baseline), `sourcegraph_no_deepsearch` (MCP-NoDeepSearch), `sourcegraph_hybrid` (MCP-Full)
- MCP tool names follow pattern `mcp__sourcegraph__sg_<tool_name>`
- Source configs are at `~/evals/custom_agents/agents/claudecode/configs/`
- Run outputs are at `~/evals/custom_agents/agents/claudecode/runs/official/`
- This repo has no build/lint/test CI — quality checks are manual review of created files

---

## 2026-02-01 - US-001
- Created `docs/CONFIGS.md` documenting the 3 agent configurations with exact tool lists
- Files changed: `docs/CONFIGS.md` (new)
- **Learnings for future iterations:**
  - The agent source code at `claude_baseline_agent.py` lines 97-480 contains all config logic
  - `sourcegraph_hybrid` system prompt claims "14 tools" but only 13 distinct tool names are registered in the allowed_tools list (lines 458-472)
  - `sourcegraph_no_deepsearch` uses the same MCP endpoint as `sourcegraph_hybrid` but blocks `sg_deepsearch` and `sg_deepsearch_read` via `--disallowedTools`
  - Hybrid modes (`sourcegraph_hybrid`, `sourcegraph_no_deepsearch`, `deepsearch_hybrid`, `none`) do NOT restrict local tools
  - Non-hybrid modes (`sourcegraph`, `deepsearch`) block local search tools (Grep, Glob, grep, rg, etc.)
- Shell runners use `BASELINE_MCP_TYPE=<mode> harbor run` pattern with `--jobs-dir` to separate output per config
- The original LoCoBench comparison used `deepsearch_hybrid` but the 3-config uses `sourcegraph_no_deepsearch` and `sourcegraph_hybrid`
---

## 2026-02-01 - US-002
- Created `configs/locobench_3config.yaml` with 3 MCP modes: baseline, sourcegraph_no_deepsearch, sourcegraph_hybrid
- Created `configs/locobench_3config.sh` shell runner with per-mode flags (--baseline-only, --no-deepsearch-only, --full-only)
- Files changed: `configs/locobench_3config.yaml` (new), `configs/locobench_3config.sh` (new)
- **Learnings for future iterations:**
  - Original YAML has `deepsearch_hybrid` as the MCP mode; the 3-config replaces this with `sourcegraph_no_deepsearch` + `sourcegraph_hybrid`
  - The YAML has a note that LoCoBench is local and not in Harbor registry — the shell script is the actual execution mechanism
  - Original shell script had 50 task IDs in a flat array (no category comments matching YAML's structure)
  - Shell runners set `CATEGORY` defaulting to `experiment` in original; changed to `official` for 3-config
  - Model is already pinned to `anthropic/claude-opus-4-5-20251101` in the original
---

## 2026-02-01 - US-003
- Created `configs/swebenchpro_3config.yaml` with 3 MCP modes: baseline, sourcegraph_no_deepsearch, sourcegraph_hybrid
- Created `configs/swebenchpro_3config.sh` shell runner with per-mode flags (--baseline-only, --no-deepsearch-only, --full-only)
- Files changed: `configs/swebenchpro_3config.yaml` (new), `configs/swebenchpro_3config.sh` (new)
- **Learnings for future iterations:**
  - SWE-bench Pro uses `--dataset swebenchpro` with `-t <task_id>` args (Harbor registry tasks), unlike LoCoBench which uses `--path` with local dirs
  - Original YAML listed "Flipt (10 tasks)" in comments but actually has 12 Flipt task IDs
  - Original shell runner used `deepsearch` as MCP mode name; 3-config replaces with `sourcegraph_no_deepsearch` + `sourcegraph_hybrid`
  - Original shell runner had `CATEGORY=experiment`; 3-config uses `official`
  - SWE-bench Pro uses 7200s (2hr) timeout vs LoCoBench's 3600s (1hr) due to heavier test suites
---

## 2026-02-01 - US-004
- Created `configs/bigcode_3config.yaml` with 3 MCP modes: baseline, sourcegraph_no_deepsearch, sourcegraph_hybrid
- Created `configs/bigcode_3config.sh` shell runner with per-mode flags (--baseline-only, --no-deepsearch-only, --full-only)
- Set concurrency to 1 (serial execution) and run_category to official
- Files changed: `configs/bigcode_3config.yaml` (new), `configs/bigcode_3config.sh` (new)
- **Learnings for future iterations:**
  - BigCode MCP is a local benchmark (not in Harbor registry), so YAML is reference only — shell script is the execution mechanism
  - Original had only 2 modes (baseline, sourcegraph_hybrid); 3-config adds sourcegraph_no_deepsearch
  - BigCode shell runner uses `declare -A TASK_SG_REPO_NAMES` to map task IDs to Sourcegraph repo names (e.g., `sg-benchmarks/kubernetes--latest`)
  - SOURCEGRAPH_REPO_NAME env var must be set per-task so the agent searches the correct repo
  - BigCode uses TIMEOUT_MULTIPLIER=10 (10x default) due to large codebases
  - Original CATEGORY defaulted to `experiment`; 3-config uses `official`
---

## 2026-02-01 - US-005
- Created `configs/k8s_docs_3config.yaml` with 3 MCP modes: baseline, sourcegraph_no_deepsearch, sourcegraph_hybrid
- Created `configs/k8s_docs_3config.sh` shell runner with per-mode flags (--baseline-only, --no-deepsearch-only, --full-only)
- Set timeout to 900s per task (matching task.toml time_limit_sec), TIMEOUT_MULTIPLIER=3
- All 5 task IDs included: pkg-doc-001, client-go-doc-001, applyconfig-doc-001, apiserver-doc-001, fairqueuing-doc-001
- Files changed: `configs/k8s_docs_3config.yaml` (new), `configs/k8s_docs_3config.sh` (new)
- **Learnings for future iterations:**
  - K8s Docs is a local benchmark like LoCoBench, uses `--path` not `--dataset`
  - task.toml has `time_limit_sec = 900` (15 min) — much shorter than LoCoBench (3600s) or SWE-bench (7200s)
  - K8s Docs tasks include an MCP config setup script in task.toml `environment.setup_scripts.mcp_config` — this is separate from the Harbor agent-level MCP setup
  - All tasks are Go language, category is "package-documentation"
  - TIMEOUT_MULTIPLIER=3 provides adequate headroom for 900s tasks (compared to LoCoBench's 10x for 3600s)
---
