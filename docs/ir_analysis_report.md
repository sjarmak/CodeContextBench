# IR Analysis Report: Context Infrastructure Impact

*Auto-generated by CodeContextBench IR analysis pipeline*

## Executive Summary

- Context infrastructure improves retrieval quality (MRR) by **+45%** (IDE-native: 0.303 vs Context infrastructure: 0.441), p<0.05.
- Retrieval-outcome correlation: Spearman r=0.087 (p=0.2443).
- Analysis covers **179** task runs across 20 suite-config pairs.

## Retrieval Quality

| Config | MRR | MAP | File Recall | Context Efficiency | n |
|--------|-----|-----|-------------|-------------------|---|
| IDE-native | 0.303 | 0.245 | 0.399 | 0.102 | 90 |
| Context infrastructure | 0.441 | 0.302 | 0.445 | 0.204 | 89 |

### Per-Suite Breakdown

| Suite | Config | MRR | File Recall | n |
|-------|--------|-----|-------------|---|
| ccb_codereview | IDE-native | 1.000 | 1.000 | 3 |
| ccb_codereview | Context infrastructure | 1.000 | 1.000 | 3 |
| ccb_crossrepo | IDE-native | 0.000 | 0.000 | 4 |
| ccb_crossrepo | Context infrastructure | 0.011 | 0.107 | 4 |
| ccb_enterprise | IDE-native | 0.695 | 0.825 | 10 |
| ccb_enterprise | Context infrastructure | 0.770 | 0.808 | 10 |
| ccb_governance | IDE-native | 0.746 | 0.783 | 6 |
| ccb_governance | Context infrastructure | 0.549 | 0.817 | 6 |
| ccb_k8sdocs | IDE-native | 0.767 | 0.800 | 5 |
| ccb_k8sdocs | Context infrastructure | 1.000 | 0.717 | 5 |
| ccb_largerepo | IDE-native | 0.127 | 0.778 | 3 |
| ccb_largerepo | Context infrastructure | 0.667 | 0.533 | 3 |
| ccb_linuxflbench | IDE-native | 0.634 | 1.000 | 5 |
| ccb_linuxflbench | Context infrastructure | 0.767 | 1.000 | 5 |
| ccb_pytorch | IDE-native | 0.183 | 0.273 | 11 |
| ccb_pytorch | Context infrastructure | 0.182 | 0.182 | 11 |
| ccb_swebenchpro | IDE-native | 0.069 | 0.129 | 36 |
| ccb_swebenchpro | Context infrastructure | 0.307 | 0.212 | 35 |
| ccb_tac | IDE-native | 0.143 | 0.143 | 7 |
| ccb_tac | Context infrastructure | 0.234 | 0.514 | 7 |

## Time-to-Context

| Config | TTFR (s) | TTAR (s) | Steps to First |
|--------|----------|----------|----------------|
| IDE-native | 46.8 | 63.3 | 2 |
| Context infrastructure | 18.1 | 20.8 | 4 |

## Cost Efficiency

| Config | Tokens/Relevant File | Mean Input Tokens | Mean Files Found | n |
|--------|---------------------|-------------------|-----------------|---|
| IDE-native | 353 | 490 | 1.9 | 76 |
| Context infrastructure | 47 | 245 | 2.2 | 87 |

**Delta summary:**

- Input Tokens: Context infrastructure uses **-50.0%** vs IDE-native
- Tokens Per Relevant File: Context infrastructure uses **-86.7%** vs IDE-native

## MCP Value Rankings

*Composite score: weighted z-score of retrieval lift (0.3), outcome lift (0.3), efficiency (0.25), cost (0.15)*

### Per-Suite Mean Composite

| Suite | Mean Composite |
|-------|---------------|
| ccb_largerepo | +0.675 |
| ccb_swebenchpro | +0.132 |
| ccb_k8sdocs | +0.114 |
| ccb_tac | +0.103 |
| ccb_codereview | +0.021 |
| ccb_linuxflbench | -0.034 |
| ccb_pytorch | -0.075 |
| ccb_enterprise | -0.242 |
| unknown | -0.409 |
| ccb_crossrepo | -0.575 |

### Top 10 Tasks Where Context Infrastructure Helps Most

| Task | Suite | Composite | Retrieval | Outcome | Efficiency | Cost |
|------|-------|-----------|-----------|---------|------------|------|
| big-code-k8s-001 | ccb_largerepo | +1.879 | +0.955 | +0.700 | +0.780 | +0.150 |
| instance_qutebrowser__qutebrowser-394bfa | ccb_swebenchpro | +1.856 | +0.333 | +1.000 | +0.000 | +0.000 |
| instance_gravitational__teleport-7744f72 | ccb_swebenchpro | +0.715 | +1.000 | +0.000 | +0.000 | +0.000 |
| instance_internetarchive__openlibrary-d1 | ccb_swebenchpro | +0.715 | +1.000 | +0.000 | +0.000 | +0.000 |
| instance_nodebb__nodebb-f1a80d48cc45877f | ccb_swebenchpro | +0.715 | +1.000 | +0.000 | +0.000 | -0.625 |
| instance_navidrome__navidrome-9c3b456165 | ccb_swebenchpro | +0.714 | +1.000 | +0.000 | +0.000 | -3.500 |
| lfl-nfs-117651 | ccb_linuxflbench | +0.697 | +0.208 | +0.400 | -1.378 | +0.000 |
| tac-buffer-pool-manager | ccb_tac | +0.687 | +0.077 | +0.417 | +0.000 | +0.363 |
| instance_protonmail__webclients-caf10ba9 | ccb_swebenchpro | +0.650 | +0.917 | +0.000 | +0.000 | -0.054 |
| instance_flipt-io__flipt-c188284ff0c094a | ccb_swebenchpro | +0.632 | +0.900 | +0.000 | +0.000 | -21.000 |

## Statistical Methodology

- **Retrieval metrics**: MRR, MAP, file recall computed against ground-truth files
- **Time-to-context**: TTFR/TTAR from trajectory.json (synthesized from transcript when missing)
- **Statistical tests**: Welch's t-test, Cohen's d effect size, bootstrap 95% CI
- **Correlation**: Spearman rank correlation between MRR and task reward
- **MCP value composite**: Z-score normalized weighted sum across retrieval, outcome, efficiency, cost
- **Cost efficiency**: Input tokens per relevant file found from task_metrics.json

### Statistical Test Results

Paired tasks: 89

| Metric | t-stat | p-value | Cohen's d | Magnitude | Significant |
|--------|--------|---------|-----------|-----------|-------------|
| file_recall | 0.6489 | 0.516381 | 0.0973 | negligible | No |
| mrr | 2.1393 | 0.032409 | 0.3207 | small | Yes |
| ttfr | -0.9952 | 0.319621 | -0.2912 | small | No |
| tt_all_r | -0.4125 | 0.679966 | -0.1216 | negligible | No |
