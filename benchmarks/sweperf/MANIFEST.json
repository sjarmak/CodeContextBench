{
  "benchmark_id": "sweperf",
  "benchmark_name": "SWE-Perf",
  "description": "Performance optimization benchmark tasks measuring runtime improvements.",
  "version": "1.0.0",
  "task_root": "benchmarks/sweperf",
  "evaluation_mode": "test",
  "metadata": {
    "source": "SWE-Perf"
  },
  "task_count": 3,
  "total_available_tasks": 3,
  "task_ids": [
    "sweperf-001",
    "sweperf-002",
    "sweperf-003"
  ],
  "sdlc_phases": [
    "Testing & QA"
  ],
  "languages": [
    "python"
  ],
  "canonical_selection": {
    "source": "selected_benchmark_tasks.json",
    "description": "Task list managed by scripts/select_benchmark_tasks.py.",
    "selected_count": 3,
    "total_available": 3
  }
}
