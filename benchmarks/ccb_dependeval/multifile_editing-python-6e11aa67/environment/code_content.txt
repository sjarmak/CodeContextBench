'Codex-CLI/src/prompt_file.py'
:import os
import time
import configparser

from pathlib import Path


API_KEYS_LOCATION = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'openaiapirc')

class PromptFile:
    context_source_filename = ""
    default_context_filename = "current_context.txt"
    default_file_path = os.path.join(os.path.dirname(__file__), "..", default_context_filename)
    default_config_path = os.path.join(os.path.dirname(__file__), "..", "current_context.config")

    def __init__(self, file_name, config):
        self.context_source_filename = "{}-context.txt".format(config['shell']) #  feel free to set your own default context path here
        
        self.file_path = self.default_file_path
        self.config_path = self.default_config_path

        # loading in one of the saved contexts
        if file_name != self.default_context_filename:
            self.load_context(file_name, True)

    def has_config(self):
        """
        Check if the prompt file has a corresponding config file
        """
        return os.path.isfile(self.config_path)
    
    def read_config(self):
        """
        Read the prompt config and return a dictionary
        """

        if self.has_config() == False:
            self.set_config(self.config)
            return self.config
        
        with open(self.config_path, 'r') as f:
            lines = f.readlines()

        config = {
            'engine': lines[0].split(':')[1].strip(),
            'temperature': float(lines[1].split(':')[1].strip()),
            'max_tokens': int(lines[2].split(':')[1].strip()),
            'shell': lines[3].split(':')[1].strip(),
            'multi_turn': lines[4].split(':')[1].strip(),
            'token_count': int(lines[5].split(':')[1].strip())
        }

        self.config = config
        return self.config 
    
    def set_config(self, config):
        """
        Set the prompt headers with the new config
        """
        self.config = config
        
        with open(self.config_path, 'w') as f:
            f.write('engine: {}\n'.format(self.config['engine']))
            f.write('temperature: {}\n'.format(self.config['temperature']))
            f.write('max_tokens: {}\n'.format(self.config['max_tokens']))
            f.write('shell: {}\n'.format(self.config['shell']))
            f.write('multi_turn: {}\n'.format(self.config['multi_turn']))
            f.write('token_count: {}\n'.format(self.config['token_count']))
    
    def show_config(self):
        print('\n')
        # read the dictionary into a list of # lines
        lines = []
        for key, value in self.config.items():
            lines.append('# {}: {}\n'.format(key, value))
        print(''.join(lines))
    
    def add_input_output_pair(self, user_query, prompt_response):
        """
        Add lines to file_name and update the token_count
        """

        with open(self.file_path, 'a') as f:
            f.write(user_query)
            f.write(prompt_response)
        
        if self.config['multi_turn'] == 'on':
            self.config['token_count'] += len(user_query.split()) + len(prompt_response.split())
            self.set_config(self.config)
    
    def read_prompt_file(self, input):
        """
        Get the updated prompt file
        Checks for token overflow and appends the current input

        Returns: the prompt file after appending the input
        """

        input_tokens_count = len(input.split())
        need_to_refresh = (self.config['token_count'] + input_tokens_count > 2048)

        if need_to_refresh:
            # delete first 2 lines of prompt context file
            with open(self.file_path, 'r') as f:
                lines = f.readlines()
                prompt = lines[2:] # drop first 2 lines of prompt
            with open(self.file_path, 'w') as f:
                f.writelines(prompt)

        # get input from prompt file
        with open(self.file_path, 'r') as f:
            lines = f.readlines()

        return ''.join(lines)
    
    def get_token_count(self):
        """
        Get the actual token count
        """
        token_count = 0
        if self.has_config():
            with open(self.config_path, 'r') as f:
                lines = f.readlines()
                token_count = int(lines[5].split(':')[1].strip())
        
        true_token_count = 0
        with open(self.file_path, 'r') as f:
            lines = f.readlines()
            # count the number of words in the prompt file
            for line in lines:
                true_token_count += len(line.split())
        
        if true_token_count != token_count:
            self.config['token_count'] = true_token_count
            self.set_config(self.config)
        
        return true_token_count
    
    def clear(self):
        """
        Clear the prompt file, while keeping the config
        Note: saves a copy to the deleted folder
        """
        config = self.read_config()
        filename = time.strftime("%Y-%m-%d_%H-%M-%S") + ".txt"
        with open(self.file_path, 'r') as f:
            lines = f.readlines()
            filename = os.path.join(os.path.dirname(__file__), "..", "deleted", filename)
            with Path(filename).open('w') as f:
                f.writelines(lines)
        
        # delete the prompt file
        with open(self.file_path, 'w') as f:
            f.write('')
        
        print("\n#   Context has been cleared, temporarily saved to {}".format(filename))
        self.set_config(config)
    
    def clear_last_interaction(self):
        """
        Clear the last interaction from the prompt file
        """
        with open(self.file_path, 'r') as f:
            lines = f.readlines()
            if len(lines) > 1:
                lines.pop()
                lines.pop()
                with open(self.file_path, 'w') as f:
                    f.writelines(lines)
            print("\n#   Unlearned interaction")
    
    def save_to(self, save_name):
        """
        Save the prompt file to a new location with the config
        """
        if not save_name.endswith('.txt'):
            save_name = save_name + '.txt'
        save_path = os.path.join(os.path.dirname(__file__), "..", "contexts", save_name)

        # first write the config
        with open(self.config_path, 'r') as f:
            lines = f.readlines()
            lines = ['## ' + line for line in lines]
            with Path(save_path).open('w') as f:
                f.writelines(lines)
        
        # then write the prompt file
        with open(self.file_path, 'r') as f:
            lines = f.readlines()
            with Path(save_path).open('a') as f:
                f.writelines(lines)
        
        print('\n#   Context saved to {}'.format(save_name))
    
    def start_multi_turn(self):
        """
        Turn on context mode
        """
        self.config['multi_turn'] = 'on'
        self.set_config(self.config)
        print("\n#   Multi turn mode is on")

    
    def stop_multi_turn(self):
        """
        Turn off context mode
        """
        self.config['multi_turn'] = 'off'
        self.set_config(self.config)
        print("\n#   Multi turn mode is off")
    
    def default_context(self):
        """
        Go to default context
        """
        self.load_context(self.context_source_filename)
    
    def load_context(self, filename, initialize=False):
        """
        Loads a context file into current_context
        """
        if not filename.endswith('.txt'):
            filename = filename + '.txt'
        filepath = Path(os.path.join(os.path.dirname(__file__), "..", "contexts", filename))

        # check if the file exists
        if filepath.exists():
            with filepath.open('r') as f:
                lines = f.readlines()
            
            # read in the engine name from openaiapirc
            config = configparser.ConfigParser()
            config.read(API_KEYS_LOCATION)
            ENGINE = config['openai']['engine'].strip('"').strip("'")

            config = {
                'engine': ENGINE,
                'temperature': float(lines[1].split(':')[1].strip()),
                'max_tokens': int(lines[2].split(':')[1].strip()),
                'shell': lines[3].split(':')[1].strip(),
                'multi_turn': lines[4].split(':')[1].strip(),
                'token_count': int(lines[5].split(':')[1].strip())
            }

            # use new config if old config doesn't exist
            if initialize == False or self.has_config() == False:
                self.set_config(config)
            else:
                self.config = self.read_config()

            lines = lines[6:]

            # write to the current prompt file if we are in multi-turn mode
            if initialize == False or self.config['multi_turn'] == "off":
                with open(self.file_path, 'w') as f:
                    f.writelines(lines)
                
                if initialize == False:
                    print('\n#   Context loaded from {}'.format(filename))
        else:
            print("\n#   File not found")
            return False
'Codex-CLI/src/codex_query.py'
:#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import openai
import sys
import os
import configparser
import re
import psutil

from pathlib import Path
from prompt_file import PromptFile
from commands import get_command_result

MULTI_TURN = "off"
SHELL = ""

ENGINE = ''
TEMPERATURE = 0
MAX_TOKENS = 300

DEBUG_MODE = False

# api keys located in the same directory as this file
API_KEYS_LOCATION = os.path.join(os.path.dirname(os.path.realpath(__file__)), 'openaiapirc')

PROMPT_CONTEXT = Path(__file__).with_name('current_context.txt')


# Read the secret_key from the ini file ~/.config/openaiapirc
# The format is:
# [openai]
# organization=<organization-id>
# secret_key=<your secret key>
# engine=<engine-name>
def create_template_ini_file():
    """
    If the ini file does not exist create it and add secret_key
    """
    if not os.path.isfile(API_KEYS_LOCATION):
        print('# Please create a file at {} and add your secret key'.format(API_KEYS_LOCATION))
        print('# The format is:\n')
        print('# [openai]')
        print('# organization_id=<organization-id>')
        print('# secret_key=<your secret key>\n')
        print('# engine=<engine-id>')
        sys.exit(1)

def initialize():
    """
    Initialize openAI and shell mode
    """
    global ENGINE

    # Check if file at API_KEYS_LOCATION exists
    create_template_ini_file()
    config = configparser.ConfigParser()
    config.read(API_KEYS_LOCATION)

    openai.api_key = config['openai']['secret_key'].strip('"').strip("'")
    openai.organization = config['openai']['organization_id'].strip('"').strip("'")
    ENGINE = config['openai']['engine'].strip('"').strip("'")

    prompt_config = {
        'engine': ENGINE,
        'temperature': TEMPERATURE,
        'max_tokens': MAX_TOKENS,
        'shell': SHELL,
        'multi_turn': MULTI_TURN,
        'token_count': 0
    }
    
    return PromptFile(PROMPT_CONTEXT.name, prompt_config)

def is_sensitive_content(content):
    """
    Check if the content contains sensitive content
    Refer to https://beta.openai.com/docs/engines/content-filter for explanation
    """

    if len(content) == 0:
        return False
    
    response = openai.Completion.create(
        engine="content-filter-alpha",
        prompt = "<|endoftext|>"+content+"\n--\nLabel:",
        temperature=0,
        max_tokens=1,
        top_p=0,
        logprobs=10
        )
    
    output_label = response["choices"][0]["text"]

    # This is the probability at which we evaluate that a "2" is likely real
    # vs. should be discarded as a false positive
    toxic_threshold = -0.355

    if output_label == "2":
        # If the model returns "2", return its confidence in 2 or other output-labels
        logprobs = response["choices"][0]["logprobs"]["top_logprobs"][0]

        # If the model is not sufficiently confident in "2",
        # choose the most probable of "0" or "1"
        # Guaranteed to have a confidence for 2 since this was the selected token.
        if logprobs["2"] < toxic_threshold:
            logprob_0 = logprobs.get("0", None)
            logprob_1 = logprobs.get("1", None)

            # If both "0" and "1" have probabilities, set the output label
            # to whichever is most probable
            if logprob_0 is not None and logprob_1 is not None:
                if logprob_0 >= logprob_1:
                    output_label = "0"
                else:
                    output_label = "1"
            # If only one of them is found, set output label to that one
            elif logprob_0 is not None:
                output_label = "0"
            elif logprob_1 is not None:
                output_label = "1"

            # If neither "0" or "1" are available, stick with "2"
            # by leaving output_label unchanged.

        # if the most probable token is none of "0", "1", or "2"
        # this should be set as unsafe
        if output_label not in ["0", "1", "2"]:
            output_label = "2"

    return (output_label != "0")

def get_query(prompt_file):
    """
    uses the stdin to get user input
    input is either treated as a command or as a Codex query

    Returns: command result or context + input from stdin
    """

    # get input from terminal or stdin
    if DEBUG_MODE:
        entry = input("prompt: ") + '\n'
    else:
        entry = sys.stdin.read()
    # first we check if the input is a command
    command_result, prompt_file = get_command_result(entry, prompt_file)

    # if input is not a command, then query Codex, otherwise exit command has been run successfully
    if command_result == "":
        return entry, prompt_file
    else:
        sys.exit(0)

def detect_shell():
    global SHELL
    global PROMPT_CONTEXT

    parent_process_name = psutil.Process(os.getppid()).name()
    POWERSHELL_MODE = bool(re.fullmatch('pwsh|pwsh.exe|powershell.exe', parent_process_name))
    BASH_MODE = bool(re.fullmatch('bash|bash.exe', parent_process_name))
    ZSH_MODE = bool(re.fullmatch('zsh|zsh.exe', parent_process_name))

    SHELL = "powershell" if POWERSHELL_MODE else "bash" if BASH_MODE else "zsh" if ZSH_MODE else "unknown"

    shell_prompt_file = Path(os.path.join(os.path.dirname(__file__), "..", "contexts", "{}-context.txt".format(SHELL)))

    if shell_prompt_file.is_file():
        PROMPT_CONTEXT = shell_prompt_file

if __name__ == '__main__':
    detect_shell()
    prompt_file = initialize()

    try:
        user_query, prompt_file = get_query(prompt_file)
        
        config = prompt_file.config if prompt_file else {
            'engine': ENGINE,
            'temperature': TEMPERATURE,
            'max_tokens': MAX_TOKENS,
            'shell': SHELL,
            'multi_turn': MULTI_TURN,
            'token_count': 0
        }

        # use query prefix to prime Codex for correct scripting language
        prefix = ""
        # prime codex for the corresponding shell type
        if config['shell'] == "zsh":
            prefix = '#!/bin/zsh\n\n'
        elif config['shell'] == "bash":
            prefix = '#!/bin/bash\n\n'
        elif config['shell'] == "powershell":
            prefix = '<# powershell #>\n\n'
        elif config['shell'] == "unknown":
            print("\n#\tUnsupported shell type, please use # set shell <shell>")
        else:
            prefix = '#' + config['shell'] + '\n\n'

        codex_query = prefix + prompt_file.read_prompt_file(user_query) + user_query

        # get the response from codex
        response = openai.Completion.create(engine=config['engine'], prompt=codex_query, temperature=config['temperature'], max_tokens=config['max_tokens'], stop="#")

        completion_all = response['choices'][0]['text']

        if is_sensitive_content(user_query + '\n' + completion_all):
            print("\n#   Sensitive content detected, response has been redacted")
        else:
            print(completion_all)

            # append output to prompt context file
            if config['multi_turn'] == "on":
                if completion_all != "" or len(completion_all) > 0:
                    prompt_file.add_input_output_pair(user_query, completion_all)
        
    except FileNotFoundError:
        print('\n\n# Codex CLI error: Prompt file not found, try again')
    except openai.error.RateLimitError:
        print('\n\n# Codex CLI error: Rate limit exceeded, try later')
    except openai.error.APIConnectionError:
        print('\n\n# Codex CLI error: API connection error, are you connected to the internet?')
    except openai.error.InvalidRequestError as e:
        print('\n\n# Codex CLI error: Invalid request - ' + str(e))
    except Exception as e:
        print('\n\n# Codex CLI error: Unexpected exception - ' + str(e))

