{
  "benchmark_id": "kubernetes_docs",
  "benchmark_name": "Kubernetes Documentation Generation",
  "description": "Documentation generation tasks for the Kubernetes codebase, evaluating an agent's ability to read large Go packages and produce accurate doc.go files",
  "version": "1.0.0",
  "created_at": "2026-01-31T00:00:00Z",
  "task_root": "benchmarks/kubernetes_docs",
  "task_count": 5,
  "task_ids": [
    "pkg-doc-001",
    "apiserver-doc-001",
    "applyconfig-doc-001",
    "client-go-doc-001",
    "fairqueuing-doc-001"
  ],
  "sdlc_phases": ["Documentation"],
  "evaluation_mode": "both",
  "repo": "kubernetes/kubernetes",
  "scip_indexed": true,
  "languages": ["Go"],
  "judge_config": {
    "script": "benchmarks/kubernetes_docs/scripts/evaluate_docs.py",
    "criteria": [
      {
        "name": "Technical Accuracy",
        "weight": 0.30,
        "description": "Correctness of APIs, data structures, behavior, package/path references"
      },
      {
        "name": "Completeness",
        "weight": 0.25,
        "description": "Coverage of major concepts, edge cases, and scope appropriateness"
      },
      {
        "name": "Style Conformance",
        "weight": 0.20,
        "description": "Adherence to Go doc conventions and Kubernetes style"
      },
      {
        "name": "Ground Truth Alignment",
        "weight": 0.25,
        "description": "How well generated content aligns with reference documentation"
      }
    ],
    "supplementary_metric": "jaccard_similarity"
  },
  "metadata": {
    "source": "custom",
    "task_types": ["documentation_generation"],
    "difficulty": "medium"
  }
}
