## Codebase Patterns

### Project Structure
- Benchmark tasks in `benchmarks/ccb_*/{task_name}/` with task.toml, instruction.md, tests/test.sh
- Run results in `runs/official/` (symlink to /home/stephanie_jarmak/evals/custom_agents/agents/claudecode/runs/official)
- Task metadata in `configs/selected_benchmark_tasks.json` (array of objects with task_name, benchmark, repo, language, difficulty, mcp_benefit_score)
- Existing analysis scripts in `scripts/` — follow their patterns for scan logic, output formats, CLI args

### Trace Data Locations
- `result.json` — task outcome (reward, tokens, timing, exceptions)
- `agent/claude-code.txt` — JSONL transcript (tool calls with timing)
- `agent/trajectory.json` — structured tool usage (includes subagent calls)
- `agent/setup/stdout.txt` — Docker/build logs
- `task_metrics.json` — extracted metrics (if exists)

### Directory Layout Patterns
- Two layouts exist: `config/batch_timestamp/task__hash/` and `config/task__hash/`
- Batch timestamp dirs match regex: `^\d{4}-\d{2}-\d{2}__\d{2}-\d{2}-\d{2}`
- Task dirs contain `__` separator: `task_name__hash`
- Configs: "baseline" and "sourcegraph_full" (no more sourcegraph_base)

### MCP Tool Names in Traces
- MCP tools have `sg_` prefix: `mcp__sourcegraph__sg_keyword_search` (NOT `mcp__sourcegraph__keyword_search`)
- Deep Search tool: `mcp__sourcegraph__sg_deepsearch`

### Scan Logic Pattern (from aggregate_status.py)
- Walk runs/official/{config}/{batch_or_task}/
- Skip dirs matching: `__broken_verifier`, `validation_test`, `archive`
- Timestamp-based dedup: for duplicate (suite, config, task_name), keep latest `started_at`
- DIR_PREFIX_TO_SUITE mapping: `swebenchpro_` -> `ccb_swebenchpro`, `pytorch_` -> `ccb_pytorch`, etc.

### Cost Extraction
- CORRECT: read claude-code.txt JSONL for per-message token counts
- WRONG: use cumulative n_input_tokens from result.json (includes cache, inflates 50-100x)
- Pricing: input $15/MTok, output $75/MTok, cache_write $18.75/MTok, cache_read $1.875/MTok

### CLI Convention
- All scripts support: --help, --suite SUITE, --config CONFIG filters
- Output to stdout by default, --output FILE to write to file
- JSON output with --json flag or as default
- Use argparse for CLI parsing

## Progress

## 2026-02-15 - US-002
- Implemented workflow taxonomy module (`scripts/workflow_taxonomy.py`)
- Created methodology doc (`docs/WORKFLOW_METRICS.md`)
- Files changed: scripts/workflow_taxonomy.py (new), docs/WORKFLOW_METRICS.md (new), ralph-ent-metrics/prd.json (updated passes)
- **Learnings for future iterations:**
  - 14 benchmark suites map to 6 workflow categories — all suites covered in SUITE_TO_CATEGORY
  - Module is importable from project root via `from scripts.workflow_taxonomy import ...`
  - Time multipliers are conservative lower-bounds; cross_repo_navigation has lowest throughput (600 tok/min, 2.5 calls/min) reflecting context-switching overhead
  - The `--json` flag pattern is standard for CLI scripts in this project
---
