{
  "project": "CodeContextBench",
  "branchName": "ralph/finalize-codereview-benchmark",
  "description": "Finalize ccb_codereview benchmark: 3 tasks (Ghost/aspnetcore/cal.com) with hybrid scoring, infrastructure integration, and documentation",
  "userStories": [
    {
      "id": "US-001",
      "title": "Add codereview to generate_manifest.py",
      "description": "As a benchmark operator, I want manifest generation to recognize codereview run directories so results appear in MANIFEST.json.",
      "acceptanceCriteria": [
        "Add \"codereview_\": \"ccb_codereview\" to DIR_PREFIX_TO_SUITE dict in scripts/generate_manifest.py (currently lines 23-34)",
        "Run python3 scripts/generate_manifest.py without errors"
      ],
      "priority": 1,
      "passes": true,
      "notes": "One-line addition to the dict. Infrastructure must be in place before tasks are finalized."
    },
    {
      "id": "US-002",
      "title": "Add codereview to aggregate_status.py",
      "description": "As a benchmark operator, I want status scanning to recognize codereview run directories so /watch-benchmarks works.",
      "acceptanceCriteria": [
        "Add \"codereview_\": \"ccb_codereview\" to DIR_PREFIX_TO_SUITE dict in scripts/aggregate_status.py (currently lines 49-60)",
        "Run python3 scripts/aggregate_status.py --help without errors"
      ],
      "priority": 2,
      "passes": true,
      "notes": "One-line addition to the dict, same as US-001 but different file."
    },
    {
      "id": "US-003",
      "title": "Create ground truth defects for cr-ghost-001",
      "description": "As a benchmark author, I need to define injected defects and expected fixes for one Ghost PR so the test script has something to score against.",
      "acceptanceCriteria": [
        "Create benchmarks/ccb_codereview/cr-ghost-001/tests/expected_defects.json with 3-5 injected defects each having: file, line_start, line_end, type (bug or violation), severity, description",
        "Create benchmarks/ccb_codereview/cr-ghost-001/tests/expected_patches/ directory with one expected-content file per defect fix",
        "Defects span at least 2 different files (cross-file for MCP benefit)",
        "At least 1 functional bug and 1 compliance violation included",
        "Choose a specific Ghost PR from the benchmark-pr-mapping (3+ files changed) and pin the commit in Dockerfile"
      ],
      "priority": 3,
      "passes": true,
      "notes": "Used Ghost PR #26260 (comment likes feature, 10 files, merge commit b43bfc85). 4 defects across 3 backend files: 3 bugs + 1 compliance violation. inject_defects.sh created for Dockerfile use."
    },
    {
      "id": "US-004",
      "title": "Write cr-ghost-001 instruction.md",
      "description": "As a benchmark operator, I want cr-ghost-001's instruction.md to have a concrete task specification so agents know exactly what to do.",
      "acceptanceCriteria": [
        "Replace all TODO placeholders in benchmarks/ccb_codereview/cr-ghost-001/instruction.md",
        "Instruction specifies: the PR context, injected defect types (functional bugs + compliance violations), that agent must both fix bugs AND write review report",
        "Instruction defines expected output: fixes committed to workspace + /workspace/review.json with array of {file, line, severity, description, fix_applied}",
        "Instruction explains scoring: hybrid of detection recall and fix correctness",
        "Instruction is >= 500 characters (passes preflight length check)"
      ],
      "priority": 4,
      "passes": true,
      "notes": "3129 chars, no TODOs. Covers PR context, 3 files, defect types, review.json output format, hybrid scoring explanation."
    },
    {
      "id": "US-005",
      "title": "Write cr-ghost-001 test.sh with hybrid scoring",
      "description": "As a benchmark operator, I want cr-ghost-001's test.sh to score agents on both detection accuracy and fix quality.",
      "acceptanceCriteria": [
        "Remove placeholder SCORE=$MAX_SCORE line and WARNING message from benchmarks/ccb_codereview/cr-ghost-001/tests/test.sh",
        "Detection scoring (50% weight): parse agent's /workspace/review.json, compute precision and recall against expected_defects.json, combine as F1",
        "Fix scoring (50% weight): check agent's committed changes against expected_patches/ (file modified + key patterns present)",
        "Final score = 0.5 * detection_f1 + 0.5 * fix_score written to /logs/verifier/reward.txt",
        "Score is 0.0 if no changes detected (existing guard preserved)",
        "test.sh is executable (chmod +x)"
      ],
      "priority": 5,
      "passes": true,
      "notes": "Hybrid scorer uses inline python3 heredoc. Detection: file-path matching with F1. Fix: pattern matching per defect (NotFoundError guard, frame.options.id, cacheInvalidate, member relation). Bash+Python syntax validated."
    },
    {
      "id": "US-006",
      "title": "Update cr-ghost-001 Dockerfile to clone Ghost repo",
      "description": "As a benchmark operator, I want the Dockerfile to clone the actual Ghost repo and inject defects rather than cloning the mapping repo.",
      "acceptanceCriteria": [
        "benchmarks/ccb_codereview/cr-ghost-001/environment/Dockerfile clones TryGhost/Ghost at a pinned commit (not benchmark-pr-mapping)",
        "Dockerfile applies defect injection patches after git checkout via RUN commands",
        "Ground truth files (expected_defects.json, expected_patches/) are copied to /workspace/tests/ not /workspace/ (agent shouldn't see them)",
        "Docker build succeeds (verify with: docker build benchmarks/ccb_codereview/cr-ghost-001/environment/)"
      ],
      "priority": 6,
      "passes": true,
      "notes": "Clones TryGhost/Ghost at b43bfc85 (PR #26260). Uses --filter=blob:none --no-checkout for fast clone. Injects defects via environment/inject_defects.sh. Ground truth in /workspace/tests/. Dockerfile syntax validated with docker build --check."
    },
    {
      "id": "US-007",
      "title": "Update cr-ghost-001 task.toml with correct repo",
      "description": "As a benchmark operator, I want task.toml to reference the Ghost repo, not the mapping repo.",
      "acceptanceCriteria": [
        "benchmarks/ccb_codereview/cr-ghost-001/task.toml: repo field set to 'Ghost' (short name from TryGhost/Ghost)",
        "configs/selected_benchmark_tasks.json: cr-ghost-001 repo field updated to 'TryGhost/Ghost'",
        "JSON and TOML are valid after changes"
      ],
      "priority": 7,
      "passes": true,
      "notes": "task.toml repo='Ghost', selected_benchmark_tasks.json repo='TryGhost/Ghost'. Also fixed pre-existing trailing commas in JSON file."
    },
    {
      "id": "US-008",
      "title": "Scaffold cr-aspnetcore-001 task",
      "description": "As a benchmark operator, I want a second code review task targeting aspnetcore for C# language diversity.",
      "acceptanceCriteria": [
        "Create benchmarks/ccb_codereview/cr-aspnetcore-001/ with task.toml, instruction.md, environment/Dockerfile, tests/test.sh",
        "task.toml has language = 'csharp', difficulty = 'hard', category = 'code-review', MCP config setup script",
        "Dockerfile clones dotnet/aspnetcore at a pinned commit and injects 3-5 defects after checkout",
        "instruction.md has concrete task specification (no TODO placeholders), specifies review.json output format",
        "tests/test.sh has hybrid scoring (same pattern as US-005) with expected_defects.json and expected_patches/",
        "test.sh is executable",
        "Registered in configs/selected_benchmark_tasks.json with correct metadata"
      ],
      "priority": 8,
      "passes": true,
      "notes": "Used dotnet/aspnetcore PR #64636 (Blazor DisplayName feature, 16 files, merge commit 8752557). 4 defects across 2 C# files: reversed attribute precedence, removed null check, broken cache invalidation, removed render optimization. inject_defects.sh uses Python string replacement."
    },
    {
      "id": "US-009",
      "title": "Scaffold cr-calcom-001 task",
      "description": "As a benchmark operator, I want a third code review task targeting cal.com for TypeScript coverage.",
      "acceptanceCriteria": [
        "Create benchmarks/ccb_codereview/cr-calcom-001/ with task.toml, instruction.md, environment/Dockerfile, tests/test.sh",
        "task.toml has language = 'typescript', difficulty = 'hard', category = 'code-review', MCP config setup script",
        "Dockerfile clones calcom/cal.com at a pinned commit and injects 3-5 defects after checkout",
        "instruction.md has concrete task specification (no TODO placeholders), specifies review.json output format",
        "tests/test.sh has hybrid scoring (same pattern as US-005) with expected_defects.json and expected_patches/",
        "test.sh is executable",
        "Registered in configs/selected_benchmark_tasks.json with correct metadata"
      ],
      "priority": 9,
      "passes": true,
      "notes": "Used cal.com PR #26801 (feature opt-in scope configuration, 8 files, merge commit 4b99072b). 4 defects across 3 TypeScript files: inverted filter condition, missing scope fallback, removed allowlist validation, hardcoded policy. inject_defects.sh uses Python string replacement."
    },
    {
      "id": "US-010",
      "title": "Update codereview_3config.sh with all tasks",
      "description": "As a benchmark operator, I want the run config to include all 3 code review tasks with correct Sourcegraph repo mappings.",
      "acceptanceCriteria": [
        "configs/codereview_3config.sh TASK_SG_REPO_NAMES array includes entries for cr-ghost-001, cr-aspnetcore-001, cr-calcom-001 pointing to their public GitHub repos",
        "Task IDs are loaded dynamically from selected_benchmark_tasks.json (already implemented)",
        "Verify script syntax: bash -n configs/codereview_3config.sh passes"
      ],
      "priority": 10,
      "passes": false,
      "notes": "Sourcegraph repo names for public repos: github.com/TryGhost/Ghost, github.com/dotnet/aspnetcore, github.com/calcom/cal.com"
    },
    {
      "id": "US-011",
      "title": "Update CLAUDE.md benchmarks table",
      "description": "As a developer reading project docs, I want to see codereview listed as a benchmark.",
      "acceptanceCriteria": [
        "Add row to benchmarks table in CLAUDE.md: | CodeReview | 3 | TS, C#, Mixed | AI code review: find & fix injected PR defects |",
        "Update header ## Benchmarks (10) to ## Benchmarks (11)"
      ],
      "priority": 11,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-012",
      "title": "Update TASK_CATALOG.md with codereview section",
      "description": "As a benchmark author, I want the task catalog to document all codereview tasks.",
      "acceptanceCriteria": [
        "Add item 11 to table of contents in docs/TASK_CATALOG.md: 11. CodeReview (3 tasks)",
        "Add full section ## 11. CodeReview -- AI Code Review with: focus description, language/repo/time-limit header, task table (task, difficulty, MCP score), per-task descriptions"
      ],
      "priority": 12,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-013",
      "title": "Update TASK_SELECTION.md with codereview coverage",
      "description": "As a benchmark methodologist, I want the selection doc to include codereview coverage.",
      "acceptanceCriteria": [
        "Add ccb_codereview row to Benchmark Coverage table in docs/TASK_SELECTION.md: | ccb_codereview | 3 | 3 | All selected (small benchmark) |",
        "Update Testing & QA count in SDLC Phase Coverage table to reflect 3 new tasks",
        "Update 'Selected **93 tasks**' count in Overview to reflect new total"
      ],
      "priority": 13,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-014",
      "title": "Run preflight validation on all codereview tasks",
      "description": "As a benchmark operator, I want all tasks to pass preflight checks before attempting runs.",
      "acceptanceCriteria": [
        "python3 scripts/validate_tasks_preflight.py --suite ccb_codereview reports ALL CHECKS PASSED",
        "Zero CRITICAL issues",
        "Zero WARNING issues"
      ],
      "priority": 14,
      "passes": false,
      "notes": "Final validation gate. Run after all tasks are created and registered."
    }
  ]
}
