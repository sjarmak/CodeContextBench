## Codebase Patterns
- crossrepo tasks use external `validate_patch.py` from Docker base image; ground truth config is in `tests/expected_changes.json` and `task.yaml`
- crossrepo tasks have sources under `/ccb_crossrepo/src/{repo_name}/` in the Docker container
- Task definitions split across: `task.toml` (Harbor config), `task.yaml` (10Figure config), `instruction.md` (agent prompt), `tests/expected_changes.json` (ground truth patterns)
- `test.sh` scripts delegate to `/ccb_crossrepo/scripts/validate_patch.py` for scoring; patterns come from task.yaml and expected_changes.json
- Config metadata lives in `configs/selected_benchmark_tasks.json`
- LargeRepo Dockerfiles already have language toolchains: golang:1.23-bookworm (k8s), Rust (servo), Python+npm (trt/vsc)
- PyTorch task.toml files use `time_limit_sec` for timeout and `difficulty` under `[task]` section
- PyTorch instruction.md files were auto-generated from PR descriptions; many have template artifacts like `#ISSUE_NUMBER` or truncated text
- Some PyTorch tasks have ground_truth_rev commits that don't match their instruction.md title - always verify by looking up both

---

## 2026-02-04 - US-001
- Fixed expected_changes.json for api_upgrade_01: replaced incorrect pointer.Int32→ptr.To Kubernetes migration with correct grpc.Dial→grpc.NewClient migration
- Updated description, expected_files (etcd, kubernetes, containerd paths), and expected_patterns (grpc.Dial/DialContext removed, grpc.NewClient added)
- Set compilation_required to true
- Files changed: benchmarks/ccb_crossrepo/api_upgrade_01/tests/expected_changes.json
- **Learnings for future iterations:**
  - The crossrepo expected_changes.json had completely wrong content (Kubernetes pointer API instead of gRPC migration) - always verify ground truth matches instruction.md
  - task.yaml already had correct old_api/new_api fields; only expected_changes.json was wrong
  - validate_patch.py is external and not in this repo - changes to scoring logic must go through expected_changes.json and task.yaml
---

## 2026-02-04 - US-002
- Fixed expected_changes.json for bug_localization_01: replaced incorrect Kubernetes EventedPLEG/evented.go ground truth with correct NumPy/pandas/scikit-learn dtype compatibility bug
- Updated description, expected_files (sklearn, pandas, numpy paths), expected_content (dtype, nullable, ExtensionArray, Int64, check_array, StandardScaler), and expected_patterns
- Set compilation_required to false (bug localization task, not code changes)
- Files changed: benchmarks/ccb_crossrepo/bug_localization_01/tests/expected_changes.json
- **Learnings for future iterations:**
  - Bug localization tasks use a different expected_changes.json structure than api_upgrade tasks - they have expected_content keywords rather than removed/added patterns
  - The instruction.md explicitly lists the 4 files to trace through, which should be used as expected_files in the ground truth
  - task.yaml was already correct (repos: numpy, pandas, scikit-learn) - only expected_changes.json had wrong content (same pattern as US-001)
  - For bug localization, expected_patterns can be split into root_cause_files and entry_point_files to help differentiate scoring
---

## 2026-02-04 - US-003
- Fixed expected_changes.json for refactor_rename_01: replaced incorrect Kubernetes ProxierHealthServer→ProxyHealthServer renaming with correct Django/Flask/requests HTTPRequest class renaming
- Updated description, expected_files (django, flask, requests paths), and expected_patterns (HttpRequest/Request removed, HTTPRequest added)
- Included key files from all three libraries: request.py, wrappers.py, models.py, plus imports and test client files
- Files changed: benchmarks/ccb_crossrepo/refactor_rename_01/tests/expected_changes.json
- **Learnings for future iterations:**
  - Same pattern as US-001 and US-002: expected_changes.json had completely wrong content (Kubernetes code), while task.yaml was already correct
  - All three crossrepo tasks had the same issue - expected_changes.json was templated from Kubernetes examples and never updated
  - For refactor/rename tasks, expected_patterns should have both class definition patterns (e.g., "class HttpRequest") and general usage patterns (e.g., "HttpRequest") for comprehensive scoring
  - File paths in expected_files follow the convention: src/{repo_name}/{path_within_repo}
---

## 2026-02-04 - US-004
- Fixed crossrepo repo field metadata in configs/selected_benchmark_tasks.json
- Updated refactor_rename_01 repo from "django,flask,requests" to "Django,Flask,requests" to match proper project name casing
- Fixed trailing comma in metadata section that made JSON invalid
- Verified all 4 crossrepo tasks have correct repo fields: api_upgrade_01 (etcd,kubernetes,containerd), bug_localization_01 (numpy,pandas,scikit-learn), refactor_rename_01 (Django,Flask,requests), cross_file_reasoning_01 (kubernetes,containerd)
- Files changed: configs/selected_benchmark_tasks.json
- **Learnings for future iterations:**
  - The JSON file had a trailing comma in the metadata section making it technically invalid - always validate JSON after changes
  - Most repo fields were already correct from the original generation; only refactor_rename_01 needed casing fix
  - bug_localization_01 and refactor_rename_01 still have language="go" which is incorrect (should be "python") - this is addressed in later stories (US-009/US-010)
---

## 2026-02-04 - US-005
- Removed `time_limit_sec = 600` from sgt-008 task.toml
- Changed difficulty from "hard" to "critical" in both task.toml and selected_benchmark_tasks.json
- Files changed: benchmarks/ccb_pytorch/sgt-008/task.toml, configs/selected_benchmark_tasks.json
- **Learnings for future iterations:**
  - Removing a TOML field is a simple line deletion; no need to set to 0
  - US-006 is the same pattern (sgt-025) - apply identical changes
---

## 2026-02-04 - US-006
- Removed `time_limit_sec = 600` from sgt-025 task.toml
- Changed difficulty from "hard" to "critical" in both task.toml and selected_benchmark_tasks.json
- Files changed: benchmarks/ccb_pytorch/sgt-025/task.toml, configs/selected_benchmark_tasks.json
- **Learnings for future iterations:**
  - Identical pattern to US-005 - simple line deletion for time_limit_sec and string replacement for difficulty
  - Python 3.10 on this system doesn't have `tomllib` (added in 3.11); use `pip._vendor.tomli` as fallback for TOML validation
---

## 2026-02-04 - US-007
- Replaced all `#ISSUE_NUMBER` placeholder strings with actual PyTorch PR/issue numbers across 5 files
- sgt-002: replaced with #169497 (the PR being reverted in runtime_assert pass)
- sgt-004: replaced with #170499 (already referenced in the title, second occurrence was template duplicate)
- sgt-009: replaced with #167368 (the HOP print functionalize PR matching the instruction title); also fixed task.toml description
- sgt-012: replaced with #164048 (the issue being properly fixed, already mentioned in description text)
- Note: sgt-016 did NOT have #ISSUE_NUMBER despite being named in the story title
- Files changed: benchmarks/ccb_pytorch/sgt-002/instruction.md, sgt-004/instruction.md, sgt-009/instruction.md, sgt-009/task.toml, sgt-012/instruction.md
- **Learnings for future iterations:**
  - The `#ISSUE_NUMBER` placeholder came from PyTorch's PR template and was never filled in by original authors - this is a common pattern in auto-generated task descriptions
  - Many tasks have ground_truth_rev commits that don't match their instruction.md title (e.g., sgt-009 instruction is about HOP print but ground truth commit is about NCCL AllToAll) - use the instruction title to look up the correct PR, not the ground truth commit
  - Always grep across ALL benchmarks directories for placeholders, not just the ones named in the story - found 4 additional files beyond the 2 listed in the story
  - sgt-004 had a duplicate "Fixes #" line (one real, one placeholder) - the original PR body likely had both
---

## 2026-02-04 - US-008
- Fixed truncated descriptions in sgt-005 and sgt-010 instruction.md files
- sgt-005: Completed "Add type hint for the new " → "Add type hint for the new property" and added 2 missing change list entries (triton.py and test_triton_heuristics.py) from PR #170190
- sgt-010: Completed "Also partially covered by smoke test PR: https://g" → full URL https://github.com/pytorch/pytorch/pull/165922/files from PR #167327
- Both truncations appeared twice in each file (once in Description, once in Task section) - fixed all occurrences
- Files changed: benchmarks/ccb_pytorch/sgt-005/instruction.md, benchmarks/ccb_pytorch/sgt-010/instruction.md
- **Learnings for future iterations:**
  - Ground truth commits in the PRD don't match the instruction titles (sgt-005 commit 41835855 is for a revert PR, sgt-010 commit b002562550 is for "Add doc for Symmetric Memory") - must search by PR title instead
  - Use `gh api "search/issues?q=..."` to find PRs since `gh search` is not available in this gh version
  - Truncation in sgt-005 wasn't just the type hint text - the entire change list was truncated, missing 2 of 4 files. Always compare against the full PR body to catch all missing content
  - sgt-010 had a typo "convolutino" in the original PR body - left as-is since the instruction should match the actual PR
---

## 2026-02-04 - US-009
- Fixed language labels in SWE-bench Pro task.toml files across 236 files
- element-hq-element-web: changed language from "python" to "typescript" (56 files)
- qutebrowser: changed language from "typescript" to "python" (79 files)
- nodebb: changed language from "python" to "javascript" (44 files)
- navidrome: changed language from "python" to "go" (57 files)
- Also updated tags arrays to match the corrected language in all files
- Files changed: 236 task.toml files across benchmarks/ccb_swebenchpro/tasks/
- **Learnings for future iterations:**
  - The SWE-bench Pro task generation script assigned "python" as default language to all tasks, regardless of the actual project language
  - qutebrowser got "typescript" instead of "python" - a different error from the default, suggesting some partial language detection was attempted
  - Both `language` field and `tags` array need to be updated in sync - the tags contain the language name as the last element
  - The tasks/ directory is in .gitignore (root-level `tasks/` pattern) but files were previously force-added and are tracked by git - use `git status` not `git add` with globs to stage changes
---

## 2026-02-04 - US-010
- Fixed language labels in configs/selected_benchmark_tasks.json to match corrected task.toml values
- SWE-bench Pro entries (element-hq-element-web=typescript, qutebrowser=python, nodebb=javascript, navidrome=go) were already correct
- Fixed crossrepo entries: bug_localization_01 changed from "go" to "python" (repos: numpy, pandas, scikit-learn), refactor_rename_01 changed from "go" to "python" (repos: Django, Flask, requests)
- Updated language distribution table in docs/TASK_SELECTION.md with actual counts from JSON
- Files changed: configs/selected_benchmark_tasks.json, docs/TASK_SELECTION.md
- **Learnings for future iterations:**
  - The SWE-bench Pro language labels in selected_benchmark_tasks.json were already correct even before US-009 fixed the task.toml files - the JSON was generated with correct labels for these repos
  - The crossrepo tasks had "go" as language because the original template was based on Kubernetes (Go) - same root cause as the wrong expected_changes.json content (US-001 through US-003)
  - The original language distribution table in TASK_SELECTION.md had inflated counts (python=33, go=24, javascript=8, java=5) vs actual (python=32, go=22, javascript=5, java=2) - unclear if prior changes weren't reflected or the table was generated from a different source
---

## 2026-02-04 - US-011
- Fixed copy-paste error in big-code-vsc-001/tests/test.sh: comment said "scrollend event implementation" (copied from servo task) but actual task is "stale diagnostics after git branch switch"
- Changed comment header from "VS Code scrollend event implementation" to "VS Code stale diagnostics after git branch switch"
- Updated verification checklist items to match actual task (diagnostics, TypeScript language features, diagnostics pipeline)
- Verified all 3 other LargeRepo test scripts have correct comments matching their tasks:
  - big-code-k8s-001: "Kubernetes NoScheduleNoTraffic taint effect" ✓
  - big-code-servo-001: "Servo scrollend event implementation" ✓
  - big-code-trt-001: "TensorRT-LLM W4A8_MXFP4_INT8 quantization mode" ✓
- Files changed: benchmarks/ccb_largerepo/big-code-vsc-001/tests/test.sh
- **Learnings for future iterations:**
  - The LargeRepo test scripts were likely generated from a template starting with the servo/scrollend task, and the vsc-001 script wasn't updated
  - The test script body (actual grep patterns and scoring logic) was already correct for the diagnostics task - only the comment header was wrong
  - All 4 LargeRepo tasks have similar test.sh structure: git change detection guard → keyword grep scoring → reward calculation
---

## 2026-02-04 - US-012
- Added Go compilation checks to big-code-k8s-001/tests/test.sh
- Compilation check runs `go build` on pkg/apis/core, pkg/scheduler, and pkg/kubelet packages before keyword scoring
- Build failure sets score to 0.0 and exits early
- Added unit test execution for ./pkg/apis/core/taint/... with proper exit code handling
- Rebalanced scoring weights: taint constant=0.3, file changes=0.2, tests added=0.2, unit tests pass=0.3
- Dockerfile already uses golang:1.23-bookworm base image (Go toolchain confirmed present)
- Files changed: benchmarks/ccb_largerepo/big-code-k8s-001/tests/test.sh
- **Learnings for future iterations:**
  - The Dockerfile base image `golang:1.23-bookworm` already provides the Go toolchain - no Dockerfile changes needed
  - When checking exit codes in bash, `$?` is reset by `if` statements - use `cmd && RC=0 || RC=$?` pattern instead
  - Go test exit code 1 = test failure, exit code 2+ = package not found or build error - useful for distinguishing missing packages from actual failures
  - The `set -e` at the top means all compilation checks need explicit error handling (using `!` negation or `|| true`) to prevent the script from exiting on the first build failure
---
